{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f2fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639da678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap(url,driver):\n",
    "    \n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        cookies=driver.find_element(By.XPATH, '//*[@id=\"site-body\"]/div[2]/div/div[2]/div[3]/div/div[2]') \n",
    "        cookies.click()\n",
    "        time.sleep(3)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    tipos=[]\n",
    "    tipo = driver.find_elements(By.XPATH, '//div[@class=\"inline-flex space-x-2\"]')\n",
    "\n",
    "    for producto in tqdm(tipo, desc='Obteniendo productos'):\n",
    "            tipos.append(producto.text)\n",
    "\n",
    "            print(f'Estamos en la página {driver.current_url}')\n",
    "        \n",
    "     \n",
    "    marcas=[]\n",
    "    marca = driver.find_elements(By.XPATH, '//span[@class=\"text-blue-gray-700 font-normal text-lg hover:underline\"]')\n",
    "\n",
    "    for producto in tqdm(marca, desc='Obteniendo productos'):\n",
    "            marcas.append(producto.text)\n",
    "\n",
    "            print(f'Estamos en la página {driver.current_url}')   \n",
    "        \n",
    "    nombres=[]\n",
    "    nombre=driver.find_elements(By.XPATH, '//span[@class=\"text-blue-gray-900 font-bold leading-none text-xl hover:underline mt-0.5\"]')\n",
    "    \n",
    "    for producto in tqdm(nombre, desc='Obteniendo productos'):\n",
    "            nombres.append(producto.text)\n",
    "\n",
    "            print(f'Estamos en la página {driver.current_url}')  \n",
    "        \n",
    "        \n",
    "    return tipos, marcas , nombres\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5cf647",
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = {}\n",
    "i = 1\n",
    "while i <= 61:\n",
    "    url = f'https://skinsort.com/products/products-for-dry-skin/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        dry[i] = data\n",
    "        i += 1\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('dry.json', 'w') as file:\n",
    "    json.dump(dry, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d57110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "filename = 'oil.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        oil_data = json.load(f)\n",
    "else:\n",
    "    oil_data = []\n",
    "\n",
    "i = len(oil_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 161:\n",
    "    url = f'https://skinsort.com/products/products-for-oily-skin/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        oil_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(oil_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "filename = 'sensitive.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        sens_data = json.load(f)\n",
    "else:\n",
    "    sens_data = []\n",
    "\n",
    "i = len(sens_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 81:\n",
    "    url = f'https://skinsort.com/products/products-for-sensitive-skin/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        sens_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(sens_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb388894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "filename = 'texture.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        text_data = json.load(f)\n",
    "else:\n",
    "    text_data = []\n",
    "\n",
    "i = len(text_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 133:\n",
    "    url = f'https://skinsort.com/products/products-for-better-texture/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        text_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(text_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c63f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "filename = 'pores.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        pores_data = json.load(f)\n",
    "else:\n",
    "    pores_data = []\n",
    "\n",
    "i = len(pores_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 193:\n",
    "    url = f'https://skinsort.com/products/products-for-large-pores/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        pores_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(pores_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7af486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "filename = 'age.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        age = json.load(f)\n",
    "else:\n",
    "    age_data = []\n",
    "\n",
    "i = len(age_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 221:\n",
    "    url = f'https://skinsort.com/products/products-for-anti-aging/page/{i}'\n",
    "    data = scrap(url)\n",
    "    if data:\n",
    "        age_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(age_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "filename = 'brig.json'\n",
    "\n",
    "# Verificar si el archivo JSON existe\n",
    "if os.path.isfile(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        brig_data = json.load(f)\n",
    "else:\n",
    "    brig_data = []\n",
    "\n",
    "# Crear una única instancia del navegador Chrome\n",
    "PATH = ChromeDriverManager().install()    \n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "i = len(brig_data) + 1  # Continuar desde el último punto guardado en el archivo JSON\n",
    "\n",
    "while i <= 308:\n",
    "    url = f'https://skinsort.com/products/products-for-brightening-skin/page/{i}'\n",
    "    data = scrap(url, driver)\n",
    "    if data:\n",
    "        brig_data.append(data)\n",
    "        i += 1\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(brig_data, f)\n",
    "    else:\n",
    "        print(f'Error al obtener los datos de la página {i}. Volviendo a intentar...')\n",
    "\n",
    "# Cerrar el navegador cuando hayas terminado de analizar las páginas\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
